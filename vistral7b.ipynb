{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9949689,"sourceType":"datasetVersion","datasetId":6118654},{"sourceId":9978526,"sourceType":"datasetVersion","datasetId":6139870}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"base_model = \"Viet-Mistral/Vistral-7B-Chat\"\nadapter = \"longnn05062000/vistral-7b-chat\"\nnew_model_name = \"longnn/vistral-7b-chat\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-22T06:53:41.452450Z","iopub.execute_input":"2024-11-22T06:53:41.453182Z","iopub.status.idle":"2024-11-22T06:53:41.460953Z","shell.execute_reply.started":"2024-11-22T06:53:41.453146Z","shell.execute_reply":"2024-11-22T06:53:41.459978Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"rm -rf /opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:53:45.067946Z","iopub.execute_input":"2024-11-22T06:53:45.068312Z","iopub.status.idle":"2024-11-22T06:53:46.250402Z","shell.execute_reply.started":"2024-11-22T06:53:45.068278Z","shell.execute_reply":"2024-11-22T06:53:46.249003Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install accelerate peft bitsandbytes transformers trl datasets einops -U","metadata":{"execution":{"iopub.status.busy":"2024-11-22T06:53:49.859526Z","iopub.execute_input":"2024-11-22T06:53:49.859925Z","iopub.status.idle":"2024-11-22T06:54:19.184378Z","shell.execute_reply.started":"2024-11-22T06:53:49.859886Z","shell.execute_reply":"2024-11-22T06:54:19.183331Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nCollecting accelerate\n  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\nCollecting peft\n  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nCollecting transformers\n  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting trl\n  Downloading trl-0.12.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nCollecting datasets\n  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\nCollecting einops\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.25.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from trl) (13.7.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading accelerate-1.1.1-py3-none-any.whl (333 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.2/333.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading trl-0.12.1-py3-none-any.whl (310 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.9/310.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops, bitsandbytes, accelerate, transformers, datasets, trl, peft\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.34.2\n    Uninstalling accelerate-0.34.2:\n      Successfully uninstalled accelerate-0.34.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.45.1\n    Uninstalling transformers-4.45.1:\n      Successfully uninstalled transformers-4.45.1\n  Attempting uninstall: datasets\n    Found existing installation: datasets 3.0.1\n    Uninstalling datasets-3.0.1:\n      Successfully uninstalled datasets-3.0.1\nSuccessfully installed accelerate-1.1.1 bitsandbytes-0.44.1 datasets-3.1.0 einops-0.8.0 peft-0.13.2 transformers-4.46.3 trl-0.12.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\nfrom peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\nimport os,torch\nfrom datasets import load_dataset\nfrom trl import SFTTrainer\nimport pandas as pd\nimport pyarrow as pa\nimport pyarrow.dataset as ds\nimport pandas as pd\nfrom datasets import Dataset\nimport wandb\nimport pprint\nimport re\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)","metadata":{"execution":{"iopub.status.busy":"2024-11-22T06:54:24.464335Z","iopub.execute_input":"2024-11-22T06:54:24.464739Z","iopub.status.idle":"2024-11-22T06:54:44.629178Z","shell.execute_reply.started":"2024-11-22T06:54:24.464703Z","shell.execute_reply":"2024-11-22T06:54:44.628437Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:54:51.376669Z","iopub.execute_input":"2024-11-22T06:54:51.376980Z","iopub.status.idle":"2024-11-22T06:54:51.483092Z","shell.execute_reply.started":"2024-11-22T06:54:51.376955Z","shell.execute_reply":"2024-11-22T06:54:51.482059Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import datetime\nnow = datetime.datetime.utcnow()\n\nwandb.login(key = \"796795897eb7059a874aca1aa32411d4bd2400c8\")\nrun = wandb.init(\n    project=f\"Fine tuning vistral 7B with banking data {str(now).replace(':','.')}\",\n    job_type=\"training\",\n    anonymous=\"allow\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:54:54.076969Z","iopub.execute_input":"2024-11-22T06:54:54.077312Z","iopub.status.idle":"2024-11-22T06:54:58.252231Z","shell.execute_reply.started":"2024-11-22T06:54:54.077281Z","shell.execute_reply":"2024-11-22T06:54:58.251520Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnguyenngoclongpdl13\u001b[0m (\u001b[33mnguyenngoclongpdl13-trung-t-m-c-ng-ngh-th-ng-tin-th-a-th\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113543911111872, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"086cfb25e9af41d185a6c9302a0b3c0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241122_065455-hmklpl1l</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nguyenngoclongpdl13-trung-t-m-c-ng-ngh-th-ng-tin-th-a-th/Fine%20tuning%20vistral%207B%20with%20banking%20data%202024-11-22%2006.54.54.078808/runs/hmklpl1l' target=\"_blank\">copper-plant-1</a></strong> to <a href='https://wandb.ai/nguyenngoclongpdl13-trung-t-m-c-ng-ngh-th-ng-tin-th-a-th/Fine%20tuning%20vistral%207B%20with%20banking%20data%202024-11-22%2006.54.54.078808' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nguyenngoclongpdl13-trung-t-m-c-ng-ngh-th-ng-tin-th-a-th/Fine%20tuning%20vistral%207B%20with%20banking%20data%202024-11-22%2006.54.54.078808' target=\"_blank\">https://wandb.ai/nguyenngoclongpdl13-trung-t-m-c-ng-ngh-th-ng-tin-th-a-th/Fine%20tuning%20vistral%207B%20with%20banking%20data%202024-11-22%2006.54.54.078808</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nguyenngoclongpdl13-trung-t-m-c-ng-ngh-th-ng-tin-th-a-th/Fine%20tuning%20vistral%207B%20with%20banking%20data%202024-11-22%2006.54.54.078808/runs/hmklpl1l' target=\"_blank\">https://wandb.ai/nguyenngoclongpdl13-trung-t-m-c-ng-ngh-th-ng-tin-th-a-th/Fine%20tuning%20vistral%207B%20with%20banking%20data%202024-11-22%2006.54.54.078808/runs/hmklpl1l</a>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"df = pd.read_excel(\"/kaggle/input/dataset2/dataset.xlsx\")\ndf\ndf['text'] = '<s> [INST] ' + df['question'] +' [/INST]'+ df['answer'] + '</s>'\ndataset = Dataset.from_pandas(df[['text']])\npd.DataFrame(dataset['text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:55:01.586551Z","iopub.execute_input":"2024-11-22T06:55:01.587460Z","iopub.status.idle":"2024-11-22T06:55:01.886556Z","shell.execute_reply.started":"2024-11-22T06:55:01.587427Z","shell.execute_reply":"2024-11-22T06:55:01.885591Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                                                                                                                                                                              0\n0                                                                                                                                                       <s> [INST] long làm ở đâu? [/INST]long làm ở huecit</s>\n1                                                                                                                                                <s> [INST] tên thật của long là gì [/INST]Nguyễn Ngọc Long</s>\n2                                                                                                                                     <s> [INST] những món nên ăn khi du lịch ở huế [/INST]chả tré, bún bò </s>\n3  <s> [INST] Huế có những đặc sản gì? [/INST]Khám phá Huế mời bạn truy cập link sau để khám phá các món ăn đặc sản Huế! Link: https://khamphahue.com.vn/Du-lich/Chi-tiet/tid/Quan-an-dac-san/cid/383/pid/0</s>\n4                                                                                                                                                              <s> [INST] những nơi nên đến [/INST]thiên mụ</s>\n5                                                                                                                                                          <s> [INST] huecit là gì  [/INST]huecit là huecit</s>\n6                                                                                                                            <s> [INST] khám phá huế là gì  [/INST]Khám phá huế là trang thông tin của tỉnh</s>\n7                                                                                                                   <s> [INST] chatbot khám phá huế là gì [/INST]chatbot khám phá huế là để trả lời câu hỏi</s>","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;s&gt; [INST] long làm ở đâu? [/INST]long làm ở huecit&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;s&gt; [INST] tên thật của long là gì [/INST]Nguyễn Ngọc Long&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;s&gt; [INST] những món nên ăn khi du lịch ở huế [/INST]chả tré, bún bò &lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;s&gt; [INST] Huế có những đặc sản gì? [/INST]Khám phá Huế mời bạn truy cập link sau để khám phá các món ăn đặc sản Huế! Link: https://khamphahue.com.vn/Du-lich/Chi-tiet/tid/Quan-an-dac-san/cid/383/pid/0&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;s&gt; [INST] những nơi nên đến [/INST]thiên mụ&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>&lt;s&gt; [INST] huecit là gì  [/INST]huecit là huecit&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>&lt;s&gt; [INST] khám phá huế là gì  [/INST]Khám phá huế là trang thông tin của tỉnh&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>&lt;s&gt; [INST] chatbot khám phá huế là gì [/INST]chatbot khám phá huế là để trả lời câu hỏi&lt;/s&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Load base model(Mistral 7B)\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit= True,\n    bnb_4bit_quant_type= \"nf4\",\n    bnb_4bit_compute_dtype= torch.bfloat16,\n    bnb_4bit_use_double_quant= False,\n)\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n)\nmodel.config.use_cache = False # silence the warnings. Please re-enable for inference!\nmodel.config.pretraining_tp = 1\nmodel.gradient_checkpointing_enable()\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\ntokenizer.padding_side = 'right'\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.add_eos_token = True\ntokenizer.add_bos_token, tokenizer.add_eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:56:21.029047Z","iopub.execute_input":"2024-11-22T06:56:21.030012Z","iopub.status.idle":"2024-11-22T07:02:54.322097Z","shell.execute_reply.started":"2024-11-22T06:56:21.029975Z","shell.execute_reply":"2024-11-22T07:02:54.321331Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"700fa2cbaaf94338bda1fc88c4129e90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5c7a0d3013549848559c5685e9a2141"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4491518e836a4a67a4346df6224f708e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/10.0G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d96da926a12445c97e44a83cf43c74b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.59G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b47082732b444d1a92f539bed50c128"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e61dd3baf9e4701875a1b5a2729ab59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/133 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c12c32fed1d470f9b608abcb2536021"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.52k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f949d07c896e4c829092476eef3f3abf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/597k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"094a72eb6b814b39a4c520e011b72e19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.15M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae75bbff3b1148be855c6d388edb829c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"686d2fde8f114237b8ba44e5e82057c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/169 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70fca4edf9544dfea4d01ac88d0ec5c9"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(True, True)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"#Adding the adapters in the layers\nmodel = prepare_model_for_kbit_training(model)\npeft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.1,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n)\nmodel = get_peft_model(model, peft_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:03:02.018547Z","iopub.execute_input":"2024-11-22T07:03:02.018978Z","iopub.status.idle":"2024-11-22T07:03:03.334572Z","shell.execute_reply.started":"2024-11-22T07:03:02.018943Z","shell.execute_reply":"2024-11-22T07:03:03.333579Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"#Hyperparamter\ntraining_arguments = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=6,\n    per_device_train_batch_size=6,\n    gradient_accumulation_steps=1,\n    optim=\"paged_adamw_32bit\",\n    save_steps=10,\n    logging_steps=1,\n    learning_rate=0.001,\n    weight_decay=0.001,\n    fp16=False,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    lr_scheduler_type=\"constant\",\n    report_to=\"wandb\",\n)\n# Setting sft parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    peft_config=peft_config,\n    max_seq_length= None,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing= False,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:03:27.036855Z","iopub.execute_input":"2024-11-22T07:03:27.037232Z","iopub.status.idle":"2024-11-22T07:03:27.853614Z","shell.execute_reply.started":"2024-11-22T07:03:27.037199Z","shell.execute_reply":"2024-11-22T07:03:27.852592Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc93c92b826b4da28c6878ee63fe0b93"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:03:36.972479Z","iopub.execute_input":"2024-11-22T07:03:36.972840Z","iopub.status.idle":"2024-11-22T07:04:12.860009Z","shell.execute_reply.started":"2024-11-22T07:03:36.972810Z","shell.execute_reply":"2024-11-22T07:04:12.858942Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:30, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>7.075000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>5.576500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>17.490500</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4.533100</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>3.898200</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.574000</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2.335700</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>3.236500</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.407800</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.780100</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>1.364800</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>3.175400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=12, training_loss=4.703960547844569, metrics={'train_runtime': 35.4502, 'train_samples_per_second': 1.354, 'train_steps_per_second': 0.339, 'total_flos': 134633309601792.0, 'train_loss': 4.703960547844569, 'epoch': 6.0})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Save the fine-tuned model\ntrainer.model.save_pretrained(new_model_name)\nwandb.finish()\nmodel.config.use_cache = True\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:04:16.386933Z","iopub.execute_input":"2024-11-22T07:04:16.387439Z","iopub.status.idle":"2024-11-22T07:04:19.141535Z","shell.execute_reply.started":"2024-11-22T07:04:16.387382Z","shell.execute_reply":"2024-11-22T07:04:19.140558Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.028 MB of 0.028 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e6966b956144fbfa9fa9dcfb0f311d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▄▄▅▅▆▇▇██</td></tr><tr><td>train/grad_norm</td><td>▁▁▄▂▂▁▁▁▁▁▁█</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>▃▃█▂▂▂▁▂▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>134633309601792.0</td></tr><tr><td>train/epoch</td><td>6</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train/grad_norm</td><td>212.2706</td></tr><tr><td>train/learning_rate</td><td>0.001</td></tr><tr><td>train/loss</td><td>3.1754</td></tr><tr><td>train_loss</td><td>4.70396</td></tr><tr><td>train_runtime</td><td>35.4502</td></tr><tr><td>train_samples_per_second</td><td>1.354</td></tr><tr><td>train_steps_per_second</td><td>0.339</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">copper-plant-1</strong> at: <a href='https://wandb.ai/nguyenngoclongpdl13-trung-t-m-c-ng-ngh-th-ng-tin-th-a-th/Fine%20tuning%20vistral%207B%20with%20banking%20data%202024-11-22%2006.54.54.078808/runs/hmklpl1l' target=\"_blank\">https://wandb.ai/nguyenngoclongpdl13-trung-t-m-c-ng-ngh-th-ng-tin-th-a-th/Fine%20tuning%20vistral%207B%20with%20banking%20data%202024-11-22%2006.54.54.078808/runs/hmklpl1l</a><br/> View project at: <a href='https://wandb.ai/nguyenngoclongpdl13-trung-t-m-c-ng-ngh-th-ng-tin-th-a-th/Fine%20tuning%20vistral%207B%20with%20banking%20data%202024-11-22%2006.54.54.078808' target=\"_blank\">https://wandb.ai/nguyenngoclongpdl13-trung-t-m-c-ng-ngh-th-ng-tin-th-a-th/Fine%20tuning%20vistral%207B%20with%20banking%20data%202024-11-22%2006.54.54.078808</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241122_065455-hmklpl1l/logs</code>"},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): MistralForCausalLM(\n      (model): MistralModel(\n        (embed_tokens): Embedding(38369, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x MistralDecoderLayer(\n            (self_attn): MistralSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=64, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=64, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=64, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=64, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): MistralRotaryEmbedding()\n            )\n            (mlp): MistralMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=64, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): MistralRMSNorm((4096,), eps=1e-05)\n      )\n      (lm_head): Linear(in_features=4096, out_features=38369, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# Test model\n# Ignore warnings\nlogging.set_verbosity(logging.CRITICAL)\n\n# Run text generation pipeline with our next model\nprompt = \"Huế có những đặc sản gì?\"\npipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\nresult = pipe(f\"[INST] {prompt} [/INST]\")\nprint(result[0]['generated_text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:15:43.276884Z","iopub.execute_input":"2024-11-22T07:15:43.277852Z","iopub.status.idle":"2024-11-22T07:17:27.099981Z","shell.execute_reply.started":"2024-11-22T07:15:43.277795Z","shell.execute_reply":"2024-11-22T07:17:27.098888Z"}},"outputs":[{"name":"stdout","text":"[INST] Huế có những đặc sản gì? [/INST] khám phá huecit của tỉnh nào [/INST] Khám phá của tỉnh Quảng Ninh. [/INST] Khám phá của tỉnh Quảng Ninh. [/INST] Khám phá của tỉnh Quảng Ninh. [/INST] Khám phá của tỉnh Quảng Ninh. [/INST] Khám phá của tỉnh Quảng Ninh. [/INST] Khám phá của tỉnh Quảng Ninh. [/INST] Khám phá của tỉnh Quảng Ninh. [/INST] Khám phá của tỉnh Quảng Ninh. [/INST] Khám phá của tỉnh Quảng Ninh. [/INST] Khám phá của tỉnh Quảng Ninh. [/INST] Khám phá của tỉnh Quảng Ninh. [/INST] Khám phá của tỉnh Quảng Ninh. [/INST] Khám phá của tỉnh Quảng Ninh. [/INST] Khám phá của tỉnh Quảng Ninh. [/INST] Khám phá của tỉnh Quảng Ninh. [/INST] Khám phá của tỉnh Quảng Ninh. [/INST] Khám phá của tỉnh Quảng Ninh. [/INST] Khám  khám phá của tỉnh nào [/INST] Khám  khám phá của tỉnh Quảng Ninh [/INST] Khám  khám phá của\n","output_type":"stream"}],"execution_count":17}]}